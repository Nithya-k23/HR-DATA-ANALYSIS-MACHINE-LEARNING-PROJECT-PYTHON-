# -*- coding: utf-8 -*-
"""HR_DATASET.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14ElcqPhdL-4_JwASBmtLimFOb0mzpfXW

##Import libraries
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, auc,accuracy_score,classification_report,confusion_matrix,roc_auc_score
from imblearn.over_sampling import SMOTE

"""##Ignore warnings

"""

import warnings
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

"""##Load Dataset"""

#Load Dataset
df=pd.read_excel("/content/drive/MyDrive/IMB553-XLS-ENG.xlsx")

#Display first 5 rows of the dataset

df.head()

#Checking the shape
print(f"Shape - {df.shape}")

#Statstical Info
df.describe()

#information about dataset
df.info()

"""##Checking Null values"""

#Checking NaN values
df.isnull().sum()

"""####Droping null values"""

#Droping NaN values because it will cause less impact on the dataset
df.dropna(inplace=True)

#Checking the shape again after droping null values
print(f"Shape - {df.shape}")

#Checking dtype of dataset
df.dtypes

#Display columns
df.columns

#Renaming the column names
df = df.rename(columns={'Candidate.Ref':'Candidate_ref', 'DOJ.Extended':'DOJ_extended', 'Duration.to.accept.offer':'Accept_duration',
       'Notice.period':'Notice_period', 'Offered.band':'Offered_band', 'Pecent.hike.expected.in.CTC':'Percent_hike_expected',
       'Percent.hike.offered.in.CTC':'Percent_hike_offered', 'Percent.difference.CTC':'Percent_difference',
       'Joining.Bonus':'Joining_Bonus', 'Candidate.relocate.actual':'Relocated','Candidate.Source':'Source','Rex.in.Yrs':'Rex'})

#Checking renamed columns
print(df.columns)

#Rearranging Columns names ,
df = df[['Candidate_ref', 'Accept_duration','Notice_period','Percent_hike_expected',
         'Percent_hike_offered', 'Percent_difference','Rex','Age','DOJ_extended','Offered_band'
         ,'Joining_Bonus', 'Relocated', 'Gender','Source', 'LOB', 'Location','Status']]

#Checking rearranged dataset
df.head()

#Make a copy of dataset
df1=df.copy()

#Checking columns
df1.columns

#Extracting categorical columns
cat = ['DOJ_extended', 'Offered_band', 'Joining_Bonus',
       'Relocated', 'Gender', 'Source', 'LOB', 'Location', 'Status']

"""##Plot count plot for each attributes"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Number of categorical columns
length = len(cat)

# Create subplot grid
rows = int(np.ceil(length / 2))
fig, axes = plt.subplots(rows, 2, figsize=(12, rows * 4))
axes = axes.flatten()   # Flatten for easy indexing

for idx, col in enumerate(cat):
    sns.countplot(x=col, data=df1, ax=axes[idx])
    axes[idx].set_title(f"Count Plot of {col}")
    axes[idx].tick_params(axis='x', rotation=90)

# Remove empty subplots if length is odd
for k in range(idx+1, len(axes)):
    fig.delaxes(axes[k])

plt.tight_layout()
plt.show()

#Statstical Information
df1.describe().T

#Removing Candidate_ref columns as it is representing unique value for each candidate
df1.drop('Candidate_ref',inplace=True,axis=1)

"""##Extracting Dependent and Dependent variables"""

#Dependent variable extraction
x = df1.iloc[:,:-1]
x.head()

#Independent variable
y = df1.iloc[:,-1]
y.head()

"""##Handlining categorical values"""

#Check unique values in y
df1['Status'].unique()

#Encoding y values Joined to '0' Not Joined to '1'
y=df["Status"].map({"Joined":0,"Not Joined":1})
y.head()

#Rechecking
y.unique()

cato=['DOJ_extended', 'Offered_band', 'Joining_Bonus',
       'Relocated', 'Gender', 'Source', 'LOB', 'Location']

x = pd.get_dummies(x,columns=cato, drop_first=True)

x.head()

#Count plot for the Target variable
sns.countplot(x='Status', data=df)
plt.show()

"""##Balance datstest
####From all above observation we can observe the target variable which is "Status" is inbalance in nature which is we can observe from above plot number of candidates joined are more in number than the Not Joined once. Even though the model accuracy is good enough but the predications made are wrong we knew it. So inorder the make dataset balance in nature we shall use the Synthetic Minority Oversample TechniquE ( SMOTE ) for it to make it balance.
"""

x_res,y_res=SMOTE(k_neighbors=3).fit_resample(x,y)

#Checking balanced or not
y_res.value_counts()

#Count plot
sns.countplot(x=y_res)
plt.show()

"""From above observation we can see the **target variable which is 'y' (Status)** got balance

#Scaling
"""

col=x_res.columns
col

x_col=['Accept_duration', 'Notice_period', 'Percent_hike_expected',
       'Percent_hike_offered', 'Percent_difference', 'Rex', 'Age',
       'DOJ_extended_Yes', 'Offered_band_E1', 'Offered_band_E2',
       'Offered_band_E3', 'Joining_Bonus_Yes', 'Relocated_Yes', 'Gender_Male',
       'Source_Direct', 'Source_Employee Referral', 'LOB_BFSI', 'LOB_CSMP',
       'LOB_EAS', 'LOB_ERS', 'LOB_ETS', 'LOB_Healthcare', 'LOB_INFRA',
       'LOB_MMS', 'Location_Bangalore', 'Location_Chennai', 'Location_Cochin',
       'Location_Gurgaon', 'Location_Hyderabad', 'Location_Kolkata',
       'Location_Mumbai', 'Location_Noida', 'Location_Others',
       'Location_Pune']
for i in x_col:
 sr = StandardScaler()
 x_res[i]=sr.fit_transform(x_res[[i]])
x_res

"""##Train and Test Split"""

#Random seed
np.random.seed(1001)

#Splitting the dataset
x_res_train,x_res_test,y_res_train,y_res_test = train_test_split(x_res,y_res,test_size=0.25,random_state=42)

#Checking the shape after splitting
x_res_train.shape,x_res_test.shape,y_res_train.shape,y_res_test.shape

"""##Logistic Regression"""

#lr as Logistic class
lr = LogisticRegression()

#Fit model
lr.fit(x_res_train,y_res_train)

#Check score of the model
lr.score(x_res_train,y_res_train),lr.score(x_res_test,y_res_test)

#Predict values
y_predict=lr.predict(x_res_test)

#Checking accuracy score
print(f"Accuracy Score : {accuracy_score(y_res_test,y_predict)}")

#Checking classification_report
print(f"classification Report :\n{classification_report(y_res_test,y_predict)}")

#Checking confusion_matrix
print(f"confusion Matrix \n{confusion_matrix(y_res_test,y_predict)}")

#Checking roc_auc_score
print(f"roc_auc_score : {roc_auc_score(y_res_test,y_predict)}")

"""##Plot Confusion Metrics"""

sns.heatmap(confusion_matrix(y_res_test,y_predict),annot=True,cmap='Blues',fmt="d")
plt.xlabel('Predicted Values')
plt.ylabel('Actual Values')
plt.title('Confusion Matrix')
plt.show()

"""##Plot ROC Curve"""

# ----- ROC CURVE -----
fpr, tpr, thresholds = roc_curve(y_res_test, y_predict)
roc_auc = auc(fpr, tpr)

# Plot ROC Curve
plt.figure(figsize=(7,5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.3f}")
plt.plot([0, 1], [0, 1], linestyle="--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Logistic Regression ROC Curve")
plt.legend()
plt.show()

"""##Testing with example"""

#Coeffe--m values
lr.coef_

#intercept--c
lr.intercept_

#m1=-0.63558	 , m2=2.058491	 ,m3=-0.223961	, m4=-0.432561	, m5=-0.360414, m6=0.777262	, m7=0.11159	 m8=-1.109115	 m9=-1.468699	 m10= 1.30454
#m11=-0.256579		, m12=-0.262273		 m13= -0.311241		, m14=0.373648			,  m15=-1.294856			, m16= -0.488626		, m17= -0.553172		 ,
#m18= -0.313741			 m19= -0.261529		 m20=-0.741499
#m21= -0.324902		 , m22= -0.136498		 , m23= -0.679801		,  m24= -0.032013		 ,
# m25=-0.721709	 m26=-0.915387	 m27=-0.026134	 m28=-0.155056	m29=-0.248628	 m30= -0.15085
#m31=-0.153433  ,m32= 1.45196, m33=-0.0298	 , m34= -0.086574

#(m*x1 + m2*x2 +..... + m34*x34)+c
X_VALUE=((0.00885928*-0.63558	 + 0.42751151*2.058491	 + 0.06087429*-0.223961	 + -0.17706697*-0.432561	 +  0.07251532*-0.360414+
        -0.25326834*0.777262	+ -0.23584701*0.111592	+  0.01438444*-1.109115	+  0.1510719*-1.468699	 + 0.43194045*1.30454	+
         0.21331384*-0.256579 + 0.15598858*-0.262273	+-1.94634188*-0.311241	+ 0.13460578*0.373648	+ 0.23496713*-1.294856 +
        -0.01568331*-0.488626	+ 1.0724312*	-0.553172	 + 0.63055774*-0.313741	+ 0.63187525* -0.261529	+ 1.26110959*-0.741499+
         0.60009244*-0.324902+  0.24396824*-0.136498 +  0.83482794* -0.679801	+ -0.1907615*-0.032013	+  2.80031918*-0.721709+
         3.03746298*-0.915387+ 0.13570433*-0.026134 +  0.87095502*-0.155056 + 1.35772787*-0.248628 + 0.99833634*-0.15085+
         0.73398238*-0.153433 + 2.75324839*1.45196 + -0.10366809*-0.0298	+  0.51705896*-0.086574)+0.7311957)
X_VALUE

#(1/1+e^-(x))------------e=2.71828
print(f"actual value -- {1/(1+2.71828**(-1*(-2.25729414818609)))}")

ypredict=lr.predict([[-0.63558,	2.058491,	-0.223961,	-0.432561	,-0.360414,	0.777262,	0.11159	,-1.109115,	-1.468699,	1.30454,	-0.256579,	-0.262273,	-0.311241,	0.373648,	-1.294856,	-0.488626	,-0.553172,	-0.313741,	-0.261529,	-0.741499,
	-0.324902,	-0.136498,	-0.679801,	-0.032013,	-0.721709,	-0.915387,	-0.026134,	-0.155056,	-0.248628,	-0.15085,	-0.153433,	1.45196,	-0.0298,	-0.086574
]])
print(f"predicted value -- {ypredict}")

"""####Both comes under same category so model is trained well"""